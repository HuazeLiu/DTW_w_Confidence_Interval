{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation of four scenarios for the subsequence alignment case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we generate 4 different scenarios, we first define a function `splice_audio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splice_audio(audio, start_sec, end_sec, sr):\n",
    "  return audio[int(start_sec * sr): int(end_sec * sr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "op17no4_1981_path = Path('/Users/jeremykim/Desktop/E207/Jupyter/E207Project/train_data/Chopin_Op017No4_Ashkenazy-1981_pid9058-13.wav')\n",
    "op17no4_1995_path = Path('/Users/jeremykim/Desktop/E207/Jupyter/E207Project/train_data/Chopin_Op017No4_Block-1995_pid9064-04.wav')\n",
    "op63no3_path = Path('/Users/jeremykim/Desktop/E207/Jupyter/E207Project/train_data/Chopin_Op063No3_Morozova-2008_pid610633-04.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the audio file with `librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "op17no4_1981, sr_1 = lb.load(op17no4_1981_path)\n",
    "op17no4_1995, sr_2 = lb.load(op17no4_1995_path)\n",
    "op63no3_2008, sr_3 = lb.load(op63no3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario I: Matching\n",
    "- In this case, we use `Op17No4_1981` and `Op17No4_1995`\n",
    "- In this case, we align 30 second clip of 1981 against the complete recording of 1955"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the sampling rates of `Op17No4_1981` and `Op17No4_1995` are not the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sr_1 != sr_2:\n",
    "    op17no4_1995 = lb.resample(op17no4_1995, orig_sr=sr_2, target_sr=sr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random 30 second audio clip of Op17No4_1981\n",
    "clip_duration = 30\n",
    "clip_samples = int(clip_duration * sr_1)\n",
    "max_start = len(op17no4_1981) - clip_samples\n",
    "start_index = np.random.randint(0, max_start)\n",
    "op17no4_1981_30sec = op17no4_1981[start_index:start_index+clip_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('/Users/jeremykim/Desktop/E207/Jupyter/E207Project/Sub_Alignment_Recordings/Scenario_1/sub_align_matching_30sec_recording1.wav', op17no4_1981_30sec, sr_1)\n",
    "sf.write('/Users/jeremykim/Desktop/E207/Jupyter/E207Project/Sub_Alignment_Recordings/Scenario_1/sub_align_matching_recording2.wav', op17no4_1995, sr_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario II: Non-matching\n",
    "- In this case, we use `Op17No4_1981` and `Op63No3_2008`\n",
    "- In this case, we align 30 second clip from Op17 against the complete recording of Op63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the sampling rates of `Op17No4_1981` and `Op63No3_2008`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sr_1 != sr_3:\n",
    "    op63no3_2008 = lb.resample(op63no3_2008, orig_sr=sr_3, target_sr=sr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random 30 second audio clip of Op17No4_1981\n",
    "clip_duration = 30\n",
    "clip_samples = int(clip_duration * sr_1)\n",
    "max_start = len(op17no4_1981) - clip_samples\n",
    "start_index = np.random.randint(0, max_start)\n",
    "op17no4_1981_30sec = op17no4_1981[start_index:start_index+clip_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('/Users/jeremykim/Desktop/E207/Jupyter/E207Project/Sub_Alignment_Recordings/Scenario_2/sub_align_non_matching_30sec_recording1.wav', op17no4_1981_30sec, sr_1)\n",
    "sf.write('/Users/jeremykim/Desktop/E207/Jupyter/E207Project/Sub_Alignment_Recordings/Scenario_2/sub_align_non_matching_recording2.wav', op63no3_2008, sr_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario III: Matching with a mismatching region in the middle\n",
    "- In this case, we use `Op17No4_1981`, `Op17No4_1995` and `Op63No3_2008`\n",
    "- Recording A: Random 30 sec segment of `Op17No4_1981`, where the middle 10 sec is replaced with a random 10 sec segment from `Op63No3_2008`\n",
    "- Recording B: `Op17No4_1995`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random 30 second audio clip of Op17No4_1981\n",
    "clip_duration_op17 = 30\n",
    "clip_samples_op17 = int(clip_duration_op17 * sr_1)\n",
    "max_start_op17 = len(op17no4_1981) - clip_samples_op17\n",
    "start_index_op17 = np.random.randint(0, max_start_op17)\n",
    "op17no4_1981_30sec = op17no4_1981[start_index_op17:start_index_op17+clip_samples_op17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random 10 second audio clip of Op63No3_2008\n",
    "clip_duration_op63 = 10\n",
    "clip_samples_op63 = int(clip_duration_op63 * sr_1)\n",
    "max_start_op63 = len(op63no3_2008) - clip_samples_op63\n",
    "start_index_op63 = np.random.randint(0, max_start_op63)\n",
    "op63no3_2008_10sec = op63no3_2008[start_index_op63:start_index_op63+clip_samples_op63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splicing 10sec clip into the middle of 30sec clip\n",
    "splice_start = 10*sr_1\n",
    "splice_end = 20*sr_1\n",
    "op17no4_1981_spliced = op17no4_1981_30sec.copy()\n",
    "op17no4_1981_spliced[splice_start:splice_end] = op63no3_2008_10sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('/Users/jeremykim/Desktop/E207/Jupyter/E207Project/Sub_Alignment_Recordings/Scenario_3/sub_align_matching_spliced_recording1.wav', op17no4_1981_spliced, sr_1)\n",
    "sf.write('/Users/jeremykim/Desktop/E207/Jupyter/E207Project/Sub_Alignment_Recordings/Scenario_3/sub_align_matching_recording2.wav', op17no4_1995, sr_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario IV: Non-Matching with a matching region in the middle\n",
    "- In this case, we use `Op17No4_1981`, `Op17No4_1995` and `Op63No3_2008`\n",
    "- Recording A: Random 30 sec segment of `Op17No4_1981`, where the middle 10 sec is replaced with a random 10 sec segment from `Op63No3_2008`\n",
    "- Recording B: `Op63No3_2008`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random 30 second audio clip of Op17No4_1981\n",
    "clip_duration_op17 = 30\n",
    "clip_samples_op17 = int(clip_duration_op17 * sr_1)\n",
    "max_start_op17 = len(op17no4_1981) - clip_samples_op17\n",
    "start_index_op17 = np.random.randint(0, max_start_op17)\n",
    "op17no4_1981_30sec = op17no4_1981[start_index_op17:start_index_op17+clip_samples_op17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random 10 second audio clip of Op63No3_2008\n",
    "clip_duration_op63 = 10\n",
    "clip_samples_op63 = int(clip_duration_op63 * sr_1)\n",
    "max_start_op63 = len(op63no3_2008) - clip_samples_op63\n",
    "start_index_op63 = np.random.randint(0, max_start_op63)\n",
    "op63no3_2008_10sec = op63no3_2008[start_index_op63:start_index_op63+clip_samples_op63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splicing 10sec clip into the middle of 30sec clip\n",
    "splice_start = 10*sr_1\n",
    "splice_end = 20*sr_1\n",
    "op17no4_1981_spliced = op17no4_1981_30sec.copy()\n",
    "op17no4_1981_spliced[splice_start:splice_end] = op63no3_2008_10sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('/Users/jeremykim/Desktop/E207/Jupyter/E207Project/Sub_Alignment_Recordings/Scenario_4/sub_align_non_matching_spliced_recording1.wav', op17no4_1981_spliced, sr_1)\n",
    "sf.write('/Users/jeremykim/Desktop/E207/Jupyter/E207Project/Sub_Alignment_Recordings/Scenario_4/sub_align_non_matching_recording2.wav', op63no3_2008, sr_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E207_Spr24",
   "language": "python",
   "name": "e207_spr24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
