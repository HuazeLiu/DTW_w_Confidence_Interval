{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_oginy1HVxlx"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vt5d4AVxVxly"
   },
   "outputs": [],
   "source": [
    "ANNOTATIONS_ROOT = Path('train_data/beat')\n",
    "AUDIO_ROOT = ('Full_Alignment_Recordings')\n",
    "FEATURES_ROOT = Path('features')\n",
    "Scenario_1_files = 'Full_Alignment_Recordings/Scenario_1'\n",
    "Scenario_2_files = 'Full_Alignment_Recordings/Scenario_2'\n",
    "Scenario_3_files = 'Full_Alignment_Recordings/Scenario_3'\n",
    "Scenario_4_files = 'Full_Alignment_Recordings/Scenario_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LUjJzfc7Vxly",
    "outputId": "a9c2a74a-e40c-46c4-95fe-f9dfccf7993b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "scenario1files = glob.glob(Scenario_1_files + \"/*\")\n",
    "scenario2files = glob.glob(Scenario_2_files + \"/*\")\n",
    "scenario3files = glob.glob(Scenario_3_files + \"/*\")\n",
    "scenario4files = glob.glob(Scenario_4_files + \"/*\")\n",
    "inFiles = []\n",
    "for file in scenario1files:\n",
    "    inFiles.append(file)\n",
    "for file in scenario2files:\n",
    "    inFiles.append(file)\n",
    "for file in scenario3files:\n",
    "    inFiles.append(file)\n",
    "for file in scenario4files:\n",
    "    inFiles.append(file)\n",
    "\n",
    "print(len(inFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qELRVSE9Vxlz"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(FEATURES_ROOT):\n",
    "    os.mkdir(FEATURES_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFe9KRHHVxlz"
   },
   "source": [
    "### Compute features on clean audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvuTWUdBVxlz"
   },
   "source": [
    "First we compute features on the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ciuh467YVxlz"
   },
   "outputs": [],
   "source": [
    "def compute_chroma_single(infile, outfile, sr = 22050, hop_length=512):\n",
    "    print('loading', infile)\n",
    "    y, sr = lb.core.load(infile, sr = sr)\n",
    "    print(infile, 'loaded')\n",
    "    # F = lb.feature.chroma_cens(y, sr=sr, hop_length=hop_length)\n",
    "    print('computing features for', infile)\n",
    "    F = lb.feature.chroma_cqt(y=y, sr=sr, hop_length=hop_length, norm=2)\n",
    "    print('saving to', outfile,'...')\n",
    "    np.save(outfile, F)\n",
    "    print('saved')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IehlRJ8oVxl0"
   },
   "outputs": [],
   "source": [
    "def compute_chroma_batch(filelist, outdir, n_cores):\n",
    "\n",
    "    # prep inputs for parallelization\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            relpath = line.strip()\n",
    "            reldir, fileid = os.path.split(relpath)\n",
    "            featdir = outdir / reldir\n",
    "            featdir.mkdir(parents=True, exist_ok=True)\n",
    "            featfile = (featdir / fileid).with_suffix('.npy')\n",
    "            audiofile = relpath\n",
    "            if os.path.exists(featfile):\n",
    "                print(f\"Skipping {featfile}\")\n",
    "            else:\n",
    "                inputs.append((audiofile, featfile))\n",
    "\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    print('computing features...')\n",
    "    pool.starmap(compute_chroma_single, inputs)\n",
    "    print('done')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2qCGdyhdVxl0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping scenario_feat/Sub_Alignment_Recordings/Scenario_1/sub_align_matching_30sec_recording1.npy\n",
      "Skipping scenario_feat/Sub_Alignment_Recordings/Scenario_1/sub_align_matching_recording2.npy\n",
      "Skipping scenario_feat/Sub_Alignment_Recordings/Scenario_2/sub_align_non_matching_30sec_recording1.npy\n",
      "Skipping scenario_feat/Sub_Alignment_Recordings/Scenario_2/sub_align_non_matching_recording2.npy\n",
      "Skipping scenario_feat/Sub_Alignment_Recordings/Scenario_3/sub_align_matching_spliced_recording1.npy\n",
      "Skipping scenario_feat/Sub_Alignment_Recordings/Scenario_3/sub_align_matching_recording2.npy\n",
      "Skipping scenario_feat/Sub_Alignment_Recordings/Scenario_4/sub_align_non_matching_spliced_recording1.npy\n",
      "Skipping scenario_feat/Sub_Alignment_Recordings/Scenario_4/sub_align_non_matching_recording2.npy\n",
      "computing features...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "compute_chroma_batch(Path(\"cfg_files/B_scenario.txt\"), Path(\"scenario_feat\"), 4) #set number of cores to 1 for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqIRx-6vVxl0"
   },
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mb6bCXyOVxl0"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mNz6nvkpVxl0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as lb\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6bfNa6rVVxl0"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "DTYPE_INT32 = np.int32\n",
    "ctypedef np.int32_t DTYPE_INT32_t\n",
    "\n",
    "DTYPE_FLOAT = np.float64\n",
    "ctypedef np.float64_t DTYPE_FLOAT_t\n",
    "\n",
    "cdef DTYPE_FLOAT_t MAX_FLOAT = float('inf')\n",
    "\n",
    "# careful, without bounds checking can mess up memory - also can't use negative indices I think (like x[-1])\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "def DTW_Cost_To_AccumCostAndSteps(Cin, parameter):\n",
    "    '''\n",
    "    Inputs\n",
    "        C: The cost Matrix\n",
    "    '''\n",
    "\n",
    "\n",
    "    '''\n",
    "    Section for checking and catching errors in the inputs\n",
    "    '''\n",
    "\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] C\n",
    "    try:\n",
    "        C = np.array(Cin, dtype=DTYPE_FLOAT)\n",
    "    except TypeError:\n",
    "        print(bcolors.FAIL + \"FAILURE: The type of the cost matrix is wrong - please pass in a 2-d numpy array\" + bcolors.ENDC)\n",
    "        return [-1, -1, -1]\n",
    "    except ValueError:\n",
    "        print(bcolors.FAIL + \"FAILURE: The type of the elements in the cost matrix is wrong - please have each element be a float (perhaps you passed in a matrix of ints?)\" + bcolors.ENDC)\n",
    "        return [-1, -1, -1]\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=1] dn\n",
    "    cdef np.ndarray[np.uint32_t, ndim=1] dm\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=1] dw\n",
    "    # make sure dn, dm, and dw are setup\n",
    "    # dn loading and exception handling\n",
    "    if ('dn'  in parameter.keys()):\n",
    "        try:\n",
    "\n",
    "            dn = np.array(parameter['dn'], dtype=np.uint32)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dn (row steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"The type of the elements in dn (row steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        dn = np.array([1, 1, 0], dtype=np.uint32)\n",
    "    # dm loading and exception handling\n",
    "    if 'dm'  in parameter.keys():\n",
    "        try:\n",
    "            dm = np.array(parameter['dm'], dtype=np.uint32)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dm (col steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of the elements in dm (col steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        print(bcolors.FAIL + \"dm (col steps) was not passed in (gave default value [1,0,1]) \" + bcolors.ENDC)\n",
    "        dm = np.array([1, 0, 1], dtype=np.uint32)\n",
    "    # dw loading and exception handling\n",
    "    if 'dw'  in parameter.keys():\n",
    "        try:\n",
    "            dw = np.array(parameter['dw'], dtype=DTYPE_FLOAT)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dw (step weights) is wrong - please pass in a 1-d numpy array that holds floats\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"FAILURE:The type of the elements in dw (step weights) is wrong - please have each element be a float (perhaps you passed ints or a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.float64)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        dw = np.array([1, 1, 1], dtype=DTYPE_FLOAT)\n",
    "        print(bcolors.FAIL + \"dw (step weights) was not passed in (gave default value [1,1,1]) \" + bcolors.ENDC)\n",
    "\n",
    "\n",
    "    '''\n",
    "    Section where types are given to the variables we're going to use\n",
    "    '''\n",
    "    # create matrices to store our results (D and E)\n",
    "    cdef DTYPE_INT32_t numRows = C.shape[0] # only works with np arrays, use np.shape(x) will work on lists? want to force to use np though?\n",
    "    cdef DTYPE_INT32_t numCols = C.shape[1]\n",
    "    cdef DTYPE_INT32_t numDifSteps = np.size(dw)\n",
    "\n",
    "    cdef unsigned int maxRowStep = max(dn)\n",
    "    cdef unsigned int maxColStep = max(dm)\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=2] steps = np.zeros((numRows,numCols), dtype=np.uint32)\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost = np.ones((maxRowStep + numRows, maxColStep + numCols), dtype=DTYPE_FLOAT) * MAX_FLOAT\n",
    "\n",
    "    cdef DTYPE_FLOAT_t bestCost\n",
    "    cdef DTYPE_INT32_t bestCostIndex\n",
    "    cdef DTYPE_FLOAT_t costForStep\n",
    "    cdef unsigned int row, col\n",
    "    cdef unsigned int stepIndex\n",
    "\n",
    "    '''\n",
    "    The start of the actual algorithm, now that all our variables are set up\n",
    "    '''\n",
    "    # initializing the cost matrix - depends on whether its subsequence DTW\n",
    "    # essentially allow us to hop on the bottom anywhere (so could start partway through one of the signals)\n",
    "    if parameter['SubSequence']:\n",
    "        for col in range(numCols):\n",
    "            accumCost[maxRowStep, col + maxColStep] = C[0, col]\n",
    "    else:\n",
    "        accumCost[maxRowStep, maxColStep] = C[0,0]\n",
    "\n",
    "    # filling the accumulated cost matrix\n",
    "    for row in range(maxRowStep, numRows + maxRowStep, 1):\n",
    "        for col in range(maxColStep, numCols + maxColStep, 1):\n",
    "            bestCost = accumCost[<unsigned int>row, <unsigned int>col] # initialize with what's there - so if is an entry point, then can start low\n",
    "            bestCostIndex = 0\n",
    "            # go through each step, find the best one\n",
    "            for stepIndex in range(numDifSteps):\n",
    "                #costForStep = accumCost[<unsigned int>(row - dn[<unsigned int>(stepIndex)]), <unsigned int>(col - dm[<unsigned int>(stepIndex)])] + dw[<unsigned int>(stepIndex)] * C[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)]\n",
    "                costForStep = accumCost[<unsigned int>((row - dn[(stepIndex)])), <unsigned int>((col - dm[(stepIndex)]))] + dw[stepIndex] * C[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)]\n",
    "                if costForStep < bestCost:\n",
    "                    bestCost = costForStep\n",
    "                    bestCostIndex = stepIndex\n",
    "            # save the best cost and best cost index\n",
    "            accumCost[row, col] = bestCost\n",
    "            steps[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)] = bestCostIndex\n",
    "\n",
    "    # return the accumulated cost along with the matrix of steps taken to achieve that cost\n",
    "    return [accumCost[maxRowStep:, maxColStep:], steps]\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "def DTW_GetPath(np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost, np.ndarray[np.uint32_t, ndim=2] stepsForCost, parameter):\n",
    "    '''\n",
    "\n",
    "    Parameter should have: 'dn', 'dm', 'dw', 'SubSequence'\n",
    "    '''\n",
    "\n",
    "    cdef np.ndarray[unsigned int, ndim=1] dn\n",
    "    cdef np.ndarray[unsigned int, ndim=1] dm\n",
    "    cdef np.uint8_t subseq\n",
    "    cdef np.int32_t startCol # added\n",
    "    # make sure dn, dm, and dw are setup\n",
    "    if ('dn'  in parameter.keys()):\n",
    "        dn = parameter['dn']\n",
    "    else:\n",
    "        dn = np.array([1, 1, 0], dtype=DTYPE_INT32)\n",
    "    if 'dm'  in parameter.keys():\n",
    "        dm = parameter['dm']\n",
    "    else:\n",
    "        dm = np.array([1, 0, 1], dtype=DTYPE_INT32)\n",
    "    if 'SubSequence' in parameter.keys():\n",
    "        subseq = parameter['SubSequence']\n",
    "    else:\n",
    "        subseq = 0\n",
    "\n",
    "    # added START\n",
    "    if 'startCol' in parameter.keys():\n",
    "        startCol = parameter['startCol']\n",
    "    else:\n",
    "        startCol = -1\n",
    "    # added END\n",
    "\n",
    "    cdef np.uint32_t numRows\n",
    "    cdef np.uint32_t numCols\n",
    "    cdef np.uint32_t curRow\n",
    "    cdef np.uint32_t curCol\n",
    "    cdef np.uint32_t endCol\n",
    "    cdef DTYPE_FLOAT_t endCost\n",
    "\n",
    "    numRows = accumCost.shape[0]\n",
    "    numCols = accumCost.shape[1]\n",
    "\n",
    "    # either start at the far corner (non sub-sequence)\n",
    "    # or start at the lowest cost entry in the last row (sub-sequence)\n",
    "    # where all of the signal along the row has been used, but only a\n",
    "    # sub-sequence of the signal along the columns has to be used\n",
    "    curRow = numRows - 1\n",
    "    if subseq:\n",
    "        curCol = np.argmin(accumCost[numRows - 1, :])\n",
    "    else:\n",
    "        curCol = numCols - 1\n",
    "\n",
    "    # added - if specified, overrides above\n",
    "    if startCol >= 0:\n",
    "        curCol = startCol\n",
    "\n",
    "    endCol = curCol\n",
    "    endCost = accumCost[curRow, curCol]\n",
    "\n",
    "    cdef np.uint32_t curRowStep\n",
    "    cdef np.uint32_t curColStep\n",
    "    cdef np.uint32_t curStepIndex\n",
    "\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=2] path = np.zeros((2, numRows + numCols), dtype=np.uint32) # make as large as could need, then chop at the end\n",
    "    path[0, 0] = curRow\n",
    "    path[1, 0] = curCol\n",
    "\n",
    "    cdef np.uint32_t stepsInPath = 1 # starts at one, we add in one before looping\n",
    "    cdef np.uint32_t stepIndex = 0\n",
    "    cdef np.int8_t done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0) \n",
    "    while not done:\n",
    "        if accumCost[curRow, curCol] == MAX_FLOAT:\n",
    "            print('A path is not possible')\n",
    "            break\n",
    "        \n",
    "        # you're done if you've made it to the bottom left (non sub-sequence)\n",
    "        # or just the bottom (sub-sequence)\n",
    "        # find the step size\n",
    "        curStepIndex = stepsForCost[curRow, curCol]\n",
    "        curRowStep = dn[curStepIndex]\n",
    "        curColStep = dm[curStepIndex]\n",
    "        # backtrack by 1 step\n",
    "        curRow = curRow - curRowStep\n",
    "        curCol = curCol - curColStep\n",
    "        # add your new location onto the path\n",
    "        path[0, stepsInPath] = curRow\n",
    "        path[1, stepsInPath] = curCol\n",
    "        stepsInPath = stepsInPath + 1\n",
    "        # check to see if you're done\n",
    "        done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0)\n",
    "\n",
    "    # reverse the path (a matrix with two rows) and return it\n",
    "    return [np.fliplr(path[:, 0:stepsInPath]), endCol, endCost]\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Tq1mQYv0Vxl1"
   },
   "outputs": [],
   "source": [
    "def alignDTW(featfile1, featfile2, steps, weights, downsample, outfile = None, profile = False, subsequence=False):\n",
    "\n",
    "    F1 = np.load(featfile1) # 12 x N\n",
    "    F2 = np.load(featfile2) # 12 x M\n",
    "    if subsequence: \n",
    "        times = []\n",
    "        times.append(time.time())\n",
    "        C = 1 - F1[:,0::downsample].T @ F2[:,0::downsample] # cos distance metric\n",
    "        times.append(time.time())\n",
    "        dn = steps[:,0].astype(np.uint32)\n",
    "        dm = steps[:,1].astype(np.uint32)\n",
    "        parameters = {'dn': dn, 'dm': dm, 'dw': weights, 'SubSequence': True}\n",
    "        [D, s] = DTW_Cost_To_AccumCostAndSteps(C, parameters)\n",
    "        times.append(time.time())\n",
    "        [wp, endCol, endCost] = DTW_GetPath(D, s, parameters)\n",
    "        times.append(time.time())\n",
    "        if outfile:\n",
    "            pickle.dump(wp, open(outfile, 'wb'))\n",
    "    else: \n",
    "        if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "            if outfile:\n",
    "                pickle.dump(None, open(outfile, 'wb'))\n",
    "            return None\n",
    "        times = []\n",
    "        times.append(time.time())\n",
    "        C = 1 - F1[:,0::downsample].T @ F2[:,0::downsample] # cos distance metric\n",
    "        times.append(time.time())\n",
    "\n",
    "        dn = steps[:,0].astype(np.uint32)\n",
    "        dm = steps[:,1].astype(np.uint32)\n",
    "        parameters = {'dn': dn, 'dm': dm, 'dw': weights, 'SubSequence': False}\n",
    "        [D, s] = DTW_Cost_To_AccumCostAndSteps(C, parameters)\n",
    "        times.append(time.time())\n",
    "        [wp, endCol, endCost] = DTW_GetPath(D, s, parameters)\n",
    "        times.append(time.time())\n",
    "        if outfile:\n",
    "            pickle.dump(wp, open(outfile, 'wb'))\n",
    "\n",
    "    if profile:\n",
    "        return wp, np.diff(times)\n",
    "    else:\n",
    "        return wp, D, C, s, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bmat_from_Dmat(D, steps, weights):\n",
    "    B = np.dstack((np.zeros_like(D),np.zeros_like(D)))\n",
    "    for i in tqdm(range(D.shape[0])):\n",
    "        for j in range(D.shape[1]):\n",
    "            bestCost = np.infty\n",
    "            bestStep = -1\n",
    "            for stepnum in range(steps.shape[0]):    \n",
    "                if i-steps[stepnum,0] < 0:\n",
    "                    pass                       \n",
    "                elif j-steps[stepnum,1] < 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    tempCost = D[i-steps[stepnum,0], j-steps[stepnum,1]]\n",
    "                    if tempCost < bestCost:\n",
    "                        bestCost = tempCost\n",
    "                        bestStep = stepnum\n",
    "            B[i,j] = [i-steps[bestStep,0], j-steps[bestStep, 1]]\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bpoint_from_Dpoint(D, steps, weights):\n",
    "    bestCost = np.infty\n",
    "    bestStep = -1\n",
    "    for stepnum in range(steps.shape[0]):    \n",
    "        if i-steps[stepnum,0] < 0:\n",
    "            pass                       \n",
    "        elif j-steps[stepnum,1] < 0:\n",
    "            pass\n",
    "        else:\n",
    "            tempCost = D[i-steps[stepnum,0], j-steps[stepnum,1]]\n",
    "            if tempCost < bestCost:\n",
    "                bestCost = tempCost\n",
    "                bestStep = stepnum\n",
    "    B[i,j] = [i-steps[bestStep,0], j-steps[bestStep, 1]]\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kI6e_cfBVxl1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1\n",
      "Scenario 2\n",
      "Scenario 3\n",
      "Scenario 4\n"
     ]
    }
   ],
   "source": [
    "scenario1Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_1\" + \"/*\")\n",
    "scenario2Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_2\" + \"/*\")\n",
    "scenario3Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_3\" + \"/*\")\n",
    "scenario4Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_4\" + \"/*\")\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "downsample = 1\n",
    "\n",
    "print('Scenario 1')\n",
    "wp1, D1, C1, s1, parameters1 = (alignDTW(scenario1Features[0], scenario1Features[1], steps, weights, downsample))\n",
    "print('Scenario 2')\n",
    "wp2, D2, C2, s2, parameters2 = (alignDTW(scenario2Features[0], scenario2Features[1], steps, weights, downsample))\n",
    "print('Scenario 3')\n",
    "wp3, D3, C3, s3, parameters3  = (alignDTW(scenario3Features[0], scenario3Features[1], steps, weights, downsample))\n",
    "print('Scenario 4')\n",
    "wp4, D4, C4, s4, parameters4 = (alignDTW(scenario4Features[0], scenario4Features[1], steps, weights, downsample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 5 -- Adding noise to the features at different SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_alignDTW(featfile1, featfile2, SNR_dB, steps, weights, downsample, outfile = None, profile = False):\n",
    "\n",
    "    F1 = np.load(featfile1) # 12 x N\n",
    "    F2 = np.load(featfile2) # 12 x M\n",
    "\n",
    "    noise_power_F1 = np.max(np.abs(F1))**2 / (10**(SNR_dB / 10))\n",
    "    noise_power_F2 = np.max(np.abs(F2))**2 / (10**(SNR_dB / 10))\n",
    "\n",
    "    noise_F1 = np.random.normal(scale=np.sqrt(noise_power_F1), size=F1.shape)\n",
    "    noise_F2 = np.random.normal(scale=np.sqrt(noise_power_F2), size=F2.shape)\n",
    "\n",
    "    F1 += noise_F1\n",
    "    F2 += noise_F2\n",
    "\n",
    "    if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "        if outfile:\n",
    "            pickle.dump(None, open(outfile, 'wb'))\n",
    "        return None\n",
    "    times = []\n",
    "    times.append(time.time())\n",
    "    C = 1 - F1[:,0::downsample].T @ F2[:,0::downsample] # cos distance metric\n",
    "    times.append(time.time())\n",
    "\n",
    "    dn = steps[:,0].astype(np.uint32)\n",
    "    dm = steps[:,1].astype(np.uint32)\n",
    "    parameters = {'dn': dn, 'dm': dm, 'dw': weights, 'SubSequence': False}\n",
    "    [D, s] = DTW_Cost_To_AccumCostAndSteps(C, parameters)\n",
    "    times.append(time.time())\n",
    "    [wp, endCol, endCost] = DTW_GetPath(D, s, parameters)\n",
    "    times.append(time.time())\n",
    "    if outfile:\n",
    "        pickle.dump(wp, open(outfile, 'wb'))\n",
    "\n",
    "    if profile:\n",
    "        return wp, np.diff(times)\n",
    "    else:\n",
    "        return wp, D, C, s, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 10dB noise to feature matrices\n",
    "SNR_dB = 10\n",
    "num_trials = 10\n",
    "scenario1Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_1\" + \"/*\")\n",
    "scenario2Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_2\" + \"/*\")\n",
    "scenario3Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_3\" + \"/*\")\n",
    "scenario4Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_4\" + \"/*\")\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "downsample = 1\n",
    "\n",
    "noisy_wp_vec_10dB = []\n",
    "noisy_D_vec_10dB = []\n",
    "noisy_C_vec_10dB = []\n",
    "noisy_s_vec_10dB = []\n",
    "noisy_parameters_vec_10dB = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "  wp1, D1, C1, s1, parameters1 = (noisy_alignDTW(scenario1Features[0], scenario1Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp2, D2, C2, s2, parameters2 = (noisy_alignDTW(scenario2Features[0], scenario2Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp3, D3, C3, s3, parameters3  = (noisy_alignDTW(scenario3Features[0], scenario3Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp4, D4, C4, s4, parameters4 = (noisy_alignDTW(scenario4Features[0], scenario4Features[1], SNR_dB, steps, weights, downsample))\n",
    "\n",
    "  noisy_wp_vec_10dB.append([wp1, wp2, wp3, wp4])\n",
    "  noisy_D_vec_10dB.append([D1, D2, D3, D4])\n",
    "  noisy_C_vec_10dB.append([C1, C2, C3, C4])\n",
    "  noisy_s_vec_10dB.append([s1, s2, s3, s4])\n",
    "  noisy_parameters_vec_10dB.append([parameters1, parameters2, parameters3, parameters4])\n",
    "\n",
    "  print(f\"Trial {i+1} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting wp y values for 4 scenarios\n",
    "for i in range(len(noisy_wp_vec_10dB)):\n",
    "  wp1_x = noisy_wp_vec_10dB[i][0][0]\n",
    "  wp2_x = noisy_wp_vec_10dB[i][1][0]\n",
    "  wp3_x = noisy_wp_vec_10dB[i][2][0]\n",
    "  wp4_x = noisy_wp_vec_10dB[i][3][0]\n",
    "\n",
    "# Extracting wp y values for 4 scenarios\n",
    "for i in range(len(noisy_wp_vec_10dB)):\n",
    "  wp1_y = noisy_wp_vec_10dB[i][0][1]\n",
    "  wp2_y = noisy_wp_vec_10dB[i][1][1]\n",
    "  wp3_y = noisy_wp_vec_10dB[i][2][1]\n",
    "  wp4_y = noisy_wp_vec_10dB[i][3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 200\n",
    "num_windows = len(wp1_y) // window_size\n",
    "std_dev_values_wp1 = []\n",
    "\n",
    "for i in range(num_windows):\n",
    "    start_idx = i * window_size\n",
    "    end_idx = (i + 1) * window_size\n",
    "    y_window = wp1_y[start_idx:end_idx]\n",
    "    std_dev_y = np.std(y_window)\n",
    "    std_dev_values_wp1.append(std_dev_y)\n",
    "\n",
    "# Getting original data at window indices\n",
    "window_indices = np.arange(0, len(wp1_x), window_size)\n",
    "windowed_wp1 = []\n",
    "for window_idx in window_indices:\n",
    "    windowed_wp1.append(wp1[1][window_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 1 10dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp1[0], wp1[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_10dB)): \n",
    "  plt.plot(noisy_wp_vec_10dB[i][0][0], noisy_wp_vec_10dB[i][0][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "#TODO: Figure out proper spacing of window_indices\n",
    "# plt.errorbar(window_indices, windowed_wp1, yerr=std_dev_values_wp1, fmt='o', label='Error Bars')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 1 10dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 2 10dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp2[0], wp2[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_10dB)): \n",
    "  plt.plot(noisy_wp_vec_10dB[i][1][0], noisy_wp_vec_10dB[i][1][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 2 10dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 3 10dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp3[0], wp3[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_10dB)): \n",
    "  plt.plot(noisy_wp_vec_10dB[i][2][0], noisy_wp_vec_10dB[i][2][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 3 10dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 4 10dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp4[0], wp4[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_10dB)): \n",
    "  plt.plot(noisy_wp_vec_10dB[i][3][0], noisy_wp_vec_10dB[i][3][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 4 10dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 0 dB noise to feature matrices\n",
    "SNR_dB = 0\n",
    "num_trials = 10\n",
    "scenario1Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_1\" + \"/*\")\n",
    "scenario2Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_2\" + \"/*\")\n",
    "scenario3Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_3\" + \"/*\")\n",
    "scenario4Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_4\" + \"/*\")\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "downsample = 1\n",
    "\n",
    "noisy_wp_vec_0dB = []\n",
    "noisy_D_vec_0dB = []\n",
    "noisy_C_vec_0dB = []\n",
    "noisy_s_vec_0dB = []\n",
    "noisy_parameters_vec_0dB = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "  wp1, D1, C1, s1, parameters1 = (noisy_alignDTW(scenario1Features[0], scenario1Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp2, D2, C2, s2, parameters2 = (noisy_alignDTW(scenario2Features[0], scenario2Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp3, D3, C3, s3, parameters3  = (noisy_alignDTW(scenario3Features[0], scenario3Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp4, D4, C4, s4, parameters4 = (noisy_alignDTW(scenario4Features[0], scenario4Features[1], SNR_dB, steps, weights, downsample))\n",
    "\n",
    "  noisy_wp_vec_0dB.append([wp1, wp2, wp3, wp4])\n",
    "  noisy_D_vec_0dB.append([D1, D2, D3, D4])\n",
    "  noisy_C_vec_0dB.append([C1, C2, C3, C4])\n",
    "  noisy_s_vec_0dB.append([s1, s2, s3, s4])\n",
    "  noisy_parameters_vec_0dB.append([parameters1, parameters2, parameters3, parameters4])\n",
    "\n",
    "  print(f\"Trial {i+1} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 1 0dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp1[0], wp1[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_0dB)): \n",
    "  plt.plot(noisy_wp_vec_0dB[i][0][0], noisy_wp_vec_0dB[i][0][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 1 0dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 2 0dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp1[0], wp1[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_0dB)): \n",
    "  plt.plot(noisy_wp_vec_0dB[i][1][0], noisy_wp_vec_0dB[i][1][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 2 0dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 3 0dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp1[0], wp1[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_0dB)): \n",
    "  plt.plot(noisy_wp_vec_0dB[i][2][0], noisy_wp_vec_0dB[i][2][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 3 0dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 4 0dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp1[0], wp1[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_0dB)): \n",
    "  plt.plot(noisy_wp_vec_0dB[i][3][0], noisy_wp_vec_0dB[i][3][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 4 0dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 5 dB noise to feature matrices\n",
    "SNR_dB = 5\n",
    "num_trials = 10\n",
    "scenario1Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_1\" + \"/*\")\n",
    "scenario2Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_2\" + \"/*\")\n",
    "scenario3Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_3\" + \"/*\")\n",
    "scenario4Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_4\" + \"/*\")\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "downsample = 1\n",
    "\n",
    "noisy_wp_vec_5dB = []\n",
    "noisy_D_vec_5dB = []\n",
    "noisy_C_vec_5dB = []\n",
    "noisy_s_vec_5dB = []\n",
    "noisy_parameters_vec_5dB = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "  wp1, D1, C1, s1, parameters1 = (noisy_alignDTW(scenario1Features[0], scenario1Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp2, D2, C2, s2, parameters2 = (noisy_alignDTW(scenario2Features[0], scenario2Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp3, D3, C3, s3, parameters3  = (noisy_alignDTW(scenario3Features[0], scenario3Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp4, D4, C4, s4, parameters4 = (noisy_alignDTW(scenario4Features[0], scenario4Features[1], SNR_dB, steps, weights, downsample))\n",
    "\n",
    "  noisy_wp_vec_5dB.append([wp1, wp2, wp3, wp4])\n",
    "  noisy_D_vec_5dB.append([D1, D2, D3, D4])\n",
    "  noisy_C_vec_5dB.append([C1, C2, C3, C4])\n",
    "  noisy_s_vec_5dB.append([s1, s2, s3, s4])\n",
    "  noisy_parameters_vec_5dB.append([parameters1, parameters2, parameters3, parameters4])\n",
    "\n",
    "  print(f\"Trial {i+1} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 1 5dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp1[0], wp1[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_5dB)): \n",
    "  plt.plot(noisy_wp_vec_5dB[i][0][0], noisy_wp_vec_5dB[i][0][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 1 5dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 2 5dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp2[0], wp2[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_5dB)): \n",
    "  plt.plot(noisy_wp_vec_5dB[i][1][0], noisy_wp_vec_5dB[i][1][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 2 5dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 3 5dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp3[0], wp3[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_5dB)): \n",
    "  plt.plot(noisy_wp_vec_5dB[i][2][0], noisy_wp_vec_5dB[i][2][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 3 5dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 4 5dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp4[0], wp4[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_5dB)): \n",
    "  plt.plot(noisy_wp_vec_5dB[i][3][0], noisy_wp_vec_5dB[i][3][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 4 5dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 2 dB noise to feature matrices\n",
    "SNR_dB = 2\n",
    "num_trials = 10\n",
    "scenario1Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_1\" + \"/*\")\n",
    "scenario2Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_2\" + \"/*\")\n",
    "scenario3Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_3\" + \"/*\")\n",
    "scenario4Features = glob.glob(\"scenario_feat/Full_Alignment_Recordings/Scenario_4\" + \"/*\")\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "downsample = 1\n",
    "\n",
    "noisy_wp_vec_2dB = []\n",
    "noisy_D_vec_2dB = []\n",
    "noisy_C_vec_2dB = []\n",
    "noisy_s_vec_2dB = []\n",
    "noisy_parameters_vec_2dB = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "  wp1, D1, C1, s1, parameters1 = (noisy_alignDTW(scenario1Features[0], scenario1Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp2, D2, C2, s2, parameters2 = (noisy_alignDTW(scenario2Features[0], scenario2Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp3, D3, C3, s3, parameters3  = (noisy_alignDTW(scenario3Features[0], scenario3Features[1], SNR_dB, steps, weights, downsample))\n",
    "  wp4, D4, C4, s4, parameters4 = (noisy_alignDTW(scenario4Features[0], scenario4Features[1], SNR_dB, steps, weights, downsample))\n",
    "\n",
    "  noisy_wp_vec_2dB.append([wp1, wp2, wp3, wp4])\n",
    "  noisy_D_vec_2dB.append([D1, D2, D3, D4])\n",
    "  noisy_C_vec_2dB.append([C1, C2, C3, C4])\n",
    "  noisy_s_vec_2dB.append([s1, s2, s3, s4])\n",
    "  noisy_parameters_vec_2dB.append([parameters1, parameters2, parameters3, parameters4])\n",
    "\n",
    "  print(f\"Trial {i+1} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 1 2dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp1[0], wp1[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_2dB)): \n",
    "  plt.plot(noisy_wp_vec_2dB[i][0][0], noisy_wp_vec_2dB[i][0][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 1 2dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 2 2dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp1[0], wp1[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_2dB)): \n",
    "  plt.plot(noisy_wp_vec_2dB[i][1][0], noisy_wp_vec_2dB[i][1][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 2 2dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 3 2dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp1[0], wp1[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_2dB)): \n",
    "  plt.plot(noisy_wp_vec_2dB[i][2][0], noisy_wp_vec_2dB[i][2][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 3 2dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scenario 4 2dB\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(wp1[0], wp1[1], label='Ground Truth Warping Path', color='blue')\n",
    "\n",
    "for i in range(len(noisy_wp_vec_2dB)): \n",
    "  plt.plot(noisy_wp_vec_2dB[i][3][0], noisy_wp_vec_2dB[i][3][1], linestyle = '--',label=f'Noisy Path {i+1}')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Scenario 4 2dB Warping Paths Overlay')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Query')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "E207_Spr24",
   "language": "python",
   "name": "e207_spr24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
